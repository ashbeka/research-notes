The increasing frequency of natural and man-made disasters necessitates post-event damage assessment and land-use analysis to enhance disaster resilience, especially during reconstruction. Disaster resilience refers to a city's ability to analyze, respond to, and recover from disasters, requiring precise insights into land-use patterns and structural damage for efficient recovery.
Current post-disaster assessment models often rely on Deep Learning methods, which, while accurate, demand significant computational resources, limiting their applicability in resource-constrained environments (Lee et al., 2023).
This research proposes a hybrid framework combining lightweight subspace methods with Deep Learning for land-use and damage classification using high-resolution satellite imagery. The goal is to create a computationally efficient model for resource-constrained recovery zones, delivering rapid, actionable insights to urban planners and deployable tools for reconstruction efforts, enhancing disaster resilience.
Damage assessment identifies infrastructure impact, while land-use analysis provides insights in spatial distribution of resources and human activity. Combining these tasks offers a comprehensive view of affected areas, enabling targeted recovery strategies, optimal resource allocation, and improved urban resilience.
The study utilizes datasets like Sentinel-2, xBD, and xView2, with preprocessing steps including noise removal, resolution alignment, and multispectral band merging. Sentinel-2 will classify land-use features (e.g., urban, rural, vegetation) using high-resolution multispectral imagery (Belgiu & Csillik, 2018). The xBD dataset, annotated for pre- and post-disaster damage assessment, will train and validate the model with augmentation to improve generalization (Gupta et al., 2019). xView2, annotated with gradual building damage levels, enhances damage classification granularity, while UAV-acquired imagery may complement satellite inputs for localized data (Xu et al., 2018).
Given that imagery from satellites or UAVs contains an immense amount of different data, The model employs Sparse Subspace Clustering (SSC) for dimensionality reduction, processing satellite imagery to preserve key structural features (Elhamifar et al., 2013). This output feeds into the U-Net model, specializing in pixel-wise classification and segmentation, enabling precise identification of damage areas and land-use categories in high-resolution imagery (Ronneberger et al., 2015). For extracting spatial features, SSC and U-Net together form a promising hybrid to improve computational efficiency and interpretability.
This hybrid framework uniquely combines SSC's efficiency in high-dimensional data preprocessing with U-Net's segmentation precision, addressing gaps in current methodologies. The model will be evaluated using metrics like precision, recall, F1 score, and Intersection over Union (IoU).
Incorporating real-time data from UAVs and IoT sensors will enhance adaptability, combining localized imagery with ground-level data (Erdelj & Natalizio, 2016). Testing will cover diverse geographic contexts, including Japanâ€™s disaster-prone regions and war-torn areas with decimated infrastructure.
The result is a scalable, deployable framework for government agencies and NGOs to improve disaster resilience and recovery. The cost-efficient AI tools developed can also be applied to disaster preparedness, infrastructure planning, smart cities, and climate change monitoring.
